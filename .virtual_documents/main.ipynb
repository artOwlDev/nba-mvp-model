years = list(range(1994, 2025))





mvps_base_url = "https://www.basketball-reference.com/awards/awards_{}.html"


# Get MVP leaderboard from every year in years.


import time
import requests


for year in years:
    url = mvps_base_url.format(year)
    data = requests.get(url) # Response
    data.encoding = data.apparent_encoding


    # Record html. (So you don't send requests every single time)
    with open("mvps/{}.html".format(year), "w+", encoding='utf-8') as f:
        f.write(data.text)

    time.sleep(5)
        


from bs4 import BeautifulSoup
import pandas as pd
from io import StringIO


dataframes = []

# Fetch mvp data from last 30 years.
for year in years:
    with open("mvps/{}.html".format(year), encoding='utf-8') as f:
        page = f.read() # Store as string

    soup = BeautifulSoup(page, "html.parser")
    soup.find('tr', class_="over_header").decompose()
    mvp_table = soup.find(id="mvp")
    mvp_table_parsed = pd.read_html(StringIO(str(mvp_table)))[0]
    mvp_table_parsed["Year"] = year
    
    dataframes.append(mvp_table_parsed)


mvps = pd.concat(dataframes)


mvps.to_csv("csv/mvps.csv")





# from selenium import webdriver
# from selenium.webdriver.chrome.service import Service
# from selenium.webdriver.chrome.options import Options
# from webdriver_manager.chrome import ChromeDriverManager

# # Path to the Brave browser executable on macOS
# brave_path = "/Applications/Google Chrome.app/Contents/MacOS/Google Chrome"

# # Set up ChromeOptions to use Brave
# options = Options()
# options.binary_location = brave_path

# driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)



# import time

# url = "https://www.basketball-reference.com/leagues/NBA_{}_per_game.html"

# for year in years:
#     driver.get(url.format(year))
#     driver.execute_script("window.scrollTo(1,10000)")
#     time.sleep(5)
#     html = driver.page_source

#     with open("players/{}.html".format(year), "w+") as f:
#         f.write(html)


# dataframes = []

for year in years:
    with open("players/{}.html".format(year)) as f:
        page = f.read()

    soup = BeautifulSoup(page, "html.parser")
    soup.find('tr', class_="thead").decompose()
    players_table = soup.find(id="per_game_stats")
    players_table_parsed = pd.read_html(StringIO(str(players_table)))[0]
    players_table_parsed["Year"] = year

    dataframes.append(players_table_parsed)


players_stats = pd.concat(dataframes)


players_stats.to_csv("csv/player_stats.csv")





team_url = "https://www.basketball-reference.com/leagues/NBA_{}_standings.html"


import time


# for year in years:
#     url = team_url.format(year)
#     data = requests.get(url)
#     time.sleep(5)

#     with open("teams/{}.html".format(year), "w+" ) as f:
#         f.write(data.text)


df = []

for year in years:
    with open("teams/{}.html".format(year)) as f:
        page = f.read()
        
    soup = BeautifulSoup(page, "html.parser")
    soup.find('tr', class_='thead').decompose()
    team_table = soup.find(id="divs_standings_E")
    team = pd.read_html(StringIO(str(team_table)))[0]
    team["Year"] = year
    team["Team"] = team["Eastern Conference"]
    del team["Eastern Conference"]
    
    df.append(team)
    
    soup = BeautifulSoup(page, "html.parser")
    soup.find('tr', class_="thead").decompose()
    team_table = soup.find(id="divs_standings_W")
    team = pd.read_html(StringIO(str(team_table)))[0]
    team["Year"] = year
    team["Team"] = team["Western Conference"]
    del team["Western Conference"]
    
    df.append(team)


teams = pd.concat(df)


teams.to_csv("csv/teams.csv")





mvps = pd.read_csv("csv/mvps.csv", encoding="utf-8")


mvps.tail(30)


mvps = mvps[["Player", "Year", "Pts Won", "Pts Max", "Share"]]


mvps


players = pd.read_csv("csv/player_stats.csv")


players


del players["Unnamed: 0"]
del players["Rk"]


players.head()


players["Player"] = players["Player"].str.replace("*", "", regex=False) # Some players have a * at the end of their name


players.head(10)


players.groupby(["Player", "Year"]).get_group(("Gary Alexander", 1994)) 


def single_row(df):
    if df.shape[0] == 1:
        return df
    else:
        row = df[df["Tm"] == "TOT"]
        row["Tm"] = df.iloc[-1,:]["Tm"]
        return row

players = players.groupby(["Player", "Year"]).apply(single_row)


players.head(20)


players.index = players.index.droplevel()


players.index = players.index.droplevel()


players.tail(100)


combined = players.merge(mvps, how="outer", on=["Player", "Year"])


combined.tail(5)


combined[["Pts Won", "Pts Max", "Share"]] = combined[["Pts Won", "Pts Max", "Share"]].fillna(0)


combined.head(5)


teams = pd.read_csv("csv/teams.csv")


teams.head(10)


teams = teams[~teams["W"].str.contains("Division")]


teams.head(10)


teams["Team"] = teams["Team"].str.replace("*", "", regex=False)


del teams["Unnamed: 0"]


teams.head(5)


teams["Team"].unique()


combined["Tm"].unique()


data = {
    "Abbreviation": ["ATL", "BRK", "BKN", "BOS", "CHA", "CHH", "CHO", "CHI", "CLE", "DAL",
                     "DEN", "DET", "GSW", "HOU", "IND", "LAC", "LAL", "MEM", "MIA", "MIL",
                     "MIN", "NJN", "NOH", "NOP", "NOK", "NYK", "OKC", "ORL", "PHI", "PHX",
                     "PHO", "POR", "SEA", "SAC", "SAS", "TOR", "UTA", "VAN", "WAS", "WSB"],
    "Name": ["Atlanta Hawks", "Brooklyn Nets", "Brooklyn Nets", "Boston Celtics", "Charlotte Bobcats",
             "Charlotte Hornets", "Charlotte Hornets", "Chicago Bulls", "Cleveland Cavaliers",
             "Dallas Mavericks", "Denver Nuggets", "Detroit Pistons", "Golden State Warriors",
             "Houston Rockets", "Indiana Pacers", "Los Angeles Clippers", "Los Angeles Lakers",
             "Memphis Grizzlies", "Miami Heat", "Milwaukee Bucks", "Minnesota Timberwolves",
             "New Jersey Nets", "New Orleans Hornets", "New Orleans Pelicans",
             "New Orleans/Oklahoma City Hornets", "New York Knicks", "Oklahoma City Thunder",
             "Orlando Magic", "Philadelphia 76ers", "Phoenix Suns", "Phoenix Suns",
             "Portland Trail Blazers", "Seattle SuperSonics", "Sacramento Kings",
             "San Antonio Spurs", "Toronto Raptors", "Utah Jazz", "Vancouver Grizzlies",
             "Washington Wizards", "Washington Bullets"]
}

team_names = pd.DataFrame(data)
team_names.to_csv("csv/teamNames.csv", index=False)


nicknames = {}

with open("csv/teamNames.csv") as f:
    lines = f.readlines()
    for line in lines[1:]:
        abb, name = line.replace("\n", "").split(",")
        nicknames[abb] = name


combined["Tm"]


combined["Team"] = combined["Tm"].map(nicknames)


combined.head(5)


stats = combined.merge(teams, how="outer", on=["Team", "Year"])


stats


stats.dtypes


stats["GB"] = stats["GB"].str.replace("â€”", "0")


stats["GB"].unique()


stats = stats.apply(pd.to_numeric, errors="ignore")


stats.dtypes


stats.to_csv("csv/train.csv")


top_scorers = stats[stats["G"] > 50].sort_values("PTS", ascending=False).head(20)


top_scorers.plot.bar("Player", "PTS")


top_scorers = stats.groupby("Year").apply(lambda x: x.sort_values("PTS", ascending=False).head(1))


top_scorers


top_scorers.plot.bar("Year", "PTS")


stats.corr(numeric_only=True)["Share"]


stats.corr(numeric_only=True)["Share"].plot.bar()





stats


pd.isnull(stats).sum()





stats[pd.isnull(stats["3P%"])][["Player", "3PA"]]


stats = stats.fillna(0)


stats.columns


training_data = ['Age', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P',
       '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB',
       'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'Year',
       'W', 'L', 'W/L%', 'GB', 'PS/G',
       'PA/G', 'SRS']


train = stats[stats["Year"] < 2024]


test = stats[stats["Year"] == 2024]


from sklearn.linear_model import Ridge


reg = Ridge(alpha=.1)


reg.fit(train[training_data], train["Share"])


predictions = reg.predict(test[training_data])


predictions = pd.DataFrame(predictions, columns=["predictions"], index=test.index)


predictions


combination = pd.concat([test[["Player", "Share"]], predictions], axis=1)


combination


combination.sort_values("Share", ascending=False).head(20)


from sklearn.metrics import mean_squared_error


mean_squared_error(combination["Share"], combination["predictions"])


combination["Share"].value_counts()


combination


combination = combination.sort_values("Share", ascending=False)


combination["Rank"] = list(range(1, combination.shape[0]+1))


combination.head(10)


combination = combination.sort_values("predictions", ascending=False)


combination["Predicted_Rank"] = list(range(1, combination.shape[0]+1))


combination.head(10)


# The program is still taking into account people who didn't get any mvp votes. Let's take the top 8

def find_rank(combination):
    actual = combination.sort_values("Share", ascending=False).head(8)
    predicted = combination.sort_values("predictions", ascending=False)
    ps = []
    found = 0
    seen = 1

    for index,row in predicted.iterrows():
        if row["Player"] in actual["Player"].values:
            found += 1
            ps.append(found/seen)
        else:
            seen += 1
    return sum(ps) / len(ps)


find_rank(combination)


years = list(range(1994, 2025))





avg_prec_score = []
all_pred = []

for year in years[5:]:
    train = stats[stats["Year"] < year]
    test = stats[stats["Year"] == year]
    reg.fit(train[training_data], train["Share"])
    predictions = reg.predict(test[training_data])
    predictions = pd.DataFrame(predictions, columns=["predictions"], index=test.index)
    combination = pd.concat([test[["Player", "Share"]], predictions], axis=1)
    all_pred.append(combination)
    avg_prec_score.append(find_rank(combination))


sum(avg_prec_score)/len(aps)


def rank(combination):
    combination = combination.sort_values("Share", ascending=False)
    combination["Rank"] = list(range(1, combination.shape[0]+1))
    combination = combination.sort_values("predictions", ascending=False)
    combination["Predicted_Rank"] = list(range(1, combination.shape[0]+1))
    combination["Difference"] = combination["Rank"] - combination["Predicted_Rank"]
    return combination


ranking = rank(all_pred[1])
ranking[ranking["Rank"] < 8].sort_values("Difference", ascending=False)


def backtest(stats, model, year, training_data):
    avg_prec_score = []
    all_pred = []
    
    for year in years[5:]:
        train = stats[stats["Year"] < year]
        test = stats[stats["Year"] == year]
        model.fit(train[training_data], train["Share"])
        predictions = reg.predict(test[training_data])
        predictions = pd.DataFrame(predictions, columns=["predictions"], index=test.index)
        combination = pd.concat([test[["Player", "Share"]], predictions], axis=1)
        combination = rank(combination)
        all_pred.append(combination)
        avg_prec_score.append(find_rank(combination))
    return sum(avg_prec_score)/len(avg_prec_score), avg_prec_score, pd.concat(all_pred)


mean_avg_prec, avg_prec_score, all_predictions = backtest(stats, reg, years[5:], training_data)


mean_avg_prec


all_predictions[all_predictions["Rank"] <= 8].sort_values("Difference").head(10)


pd.concat([pd.Series(reg.coef_), pd.Series(training_data)], axis=1).sort_values(0, ascending=False)


stat_ratios = stats[["PTS", "AST", "STL", "BLK", "3P", "Year"]].apply(lambda x: x / x.mean())


stat_ratios


stats[["PTS_TOTAL", "AST_TOTAL", "STEAL_TOTAL", "BLK_TOTAL", "3P_TOTAL"]] = stat_ratios[["PTS", "AST", "STL", "BLK", "3P"]]


stats


training_data += ["PTS_TOTAL", "AST_TOTAL", "STEAL_TOTAL", "BLK_TOTAL", "3P_TOTAL"]


mean_avg_prec, avg_prec_score, all_predictions = backtest(stats, reg, years[5:], training_data)


mean_avg_prec


stats["Num_Pos"] = stats["Pos"].astype("category").cat.codes


stats.head()


stats["Num_Team"] = stats["Tm"].astype("category").cat.codes


stats.head()


from sklearn.ensemble import RandomForestRegressor


rf = RandomForestRegressor(n_estimators=250, random_state=1, min_samples_split=5)


mean_avg_prec, avg_prec_score, all_predictions = backtest(stats, rf, years[27:], training_data)


mean_avg_prec


mean_avg_prec, avg_prec_score, all_predictions = backtest(stats, reg, years[27:], training_data)


mean_avg_prec



